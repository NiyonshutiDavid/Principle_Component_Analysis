{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formative Assignment: Advanced Linear Algebra (PCA)\n",
    "This notebook will guide you through the implementation of Principal Component Analysis (PCA). Fill in the missing code and provide the required answers in the appropriate sections. You will work with the `fuel_econ.csv` dataset.\n",
    "\n",
    "Make sure to display outputs for each code cell when submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Standardize the Data\n",
    "Before applying PCA, we must standardize the dataset. Standardization ensures that all features have a mean of 0 and a standard deviation of 1, which is essential for PCA.\n",
    "Fill in the code to standardize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Load and Standardize the data (use of numpy only allowed)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the Covariance Matrix\n",
    "The covariance matrix helps us understand how the features are related to each other. It is a key component in PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Perform Eigendecomposition\n",
    "Eigendecomposition of the covariance matrix will give us the eigenvalues and eigenvectors, which are essential for PCA.\n",
    "Fill in the code to compute the eigenvalues and eigenvectors of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Sort Principal Components\n",
    "Sort the eigenvectors based on their corresponding eigenvalues in descending order. The higher the eigenvalue, the more important the eigenvector.\n",
    "Complete the code to sort the eigenvectors and print the sorted components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Project Data onto Principal Components\n",
    "Now that weâ€™ve selected the number of components, we will project the original data onto the chosen principal components.\n",
    "Fill in the code to perform the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Output the Reduced Data\n",
    "Finally, display the reduced data obtained by projecting the original dataset onto the selected principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Visualize Before and After PCA\n",
    "Now, let's plot the original data and the data after PCA to compare the reduction in dimensions visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Standardize the data (use of numpy only allowed)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"fuel_econ.csv\")\n",
    "data = data.select_dtypes(include=[np.number])  # Keep only numerical columns\n",
    "\n",
    "# Standardizing data: (Data - Mean) / Standard Deviation\n",
    "standardized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "print(\"First few rows of standardized data:\")\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Step 2: Compute the Covariance Matrix\n",
    "cov_matrix = np.cov(standardized_data.T)\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "# Step 3: Compute Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sorting eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 4: Explained Variance and Dynamic Selection of Principal Components\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Choosing components that explain at least 95% variance\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components selected: {num_components}\")\n",
    "\n",
    "# Step 5: Project Data onto Principal Components\n",
    "principal_components = eigenvectors[:, :num_components]\n",
    "transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "print(\"\\nTransformed Data (first few rows):\")\n",
    "print(transformed_data[:5])\n",
    "\n",
    "# Step 6: Optimizing for Large Datasets (using SVD for efficiency)\n",
    "U, S, Vt = np.linalg.svd(standardized_data, full_matrices=False)\n",
    "svd_components = Vt[:num_components, :]\n",
    "transformed_svd_data = np.dot(standardized_data, svd_components)\n",
    "\n",
    "print(\"\\nSVD Transformed Data (first few rows):\")\n",
    "print(transformed_svd_data[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
